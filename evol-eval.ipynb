{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-25T21:58:35.531577300Z",
     "start_time": "2023-11-25T21:58:35.500327600Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create base dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44587620cd90102"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_prompt = \"\"\"Temp\"\"\"\n",
    "\n",
    "base_evaluations = []\n",
    "n = 10\n",
    "for i in range(n):\n",
    "    eval = None\n",
    "    base_evaluations.append(eval)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff3933e42e876d39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evolve base dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f698fb29b1ee87f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Base instructions for evolving the prompts\n",
    "base_instruction = \"\"\"I want you to act as a Prompt Rewriter.\n",
    "Your objective is to rewrite a given prompt into a more complex version to make those famous AI systems (e.g., chatgpt and GPT4) a bit harder to handle.\n",
    "But the rewritten prompt must be reasonable and must be understood and responded by humans.\n",
    "Your rewriting cannot omit the non-text parts such as the table and code in #The Given Prompt#:. Also, please do not omit the input in #The Given Prompt#.\n",
    "You SHOULD complicate the given prompt using the following method:\n",
    "{{}}\n",
    "You should try your best not to make the #Rewritten Prompt# become verbose, #Rewritten Prompt# can only add 10 to 20 words into #The Given Prompt#.\n",
    "'#The Given Prompt#', '#Rewritten Prompt#', 'given prompt' and 'rewritten prompt' are not allowed to appear in #Rewritten Prompt#\"\"\"\n",
    "\n",
    "base_instruction_breadth = \"\"\"I want you to act as a Prompt Creator.\n",
    "Your goal is to draw inspiration from the #Given Prompt# to create a brand new prompt.\n",
    "This new prompt should belong to the same domain as the #Given Prompt# but be even more rare.\n",
    "The LENGTH and complexity of the #Created Prompt# should be similar to that of the #Given Prompt#.\n",
    "The #Created Prompt# must be reasonable and must be understood and responded by humans.\n",
    "'#Given Prompt#', '#Created Prompt#', 'given prompt' and 'created prompt' are not allowed to appear in #Created Prompt#\"\"\"\n",
    "\n",
    "\n",
    "class EvalEvolver:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.operations = {\n",
    "            \"in_depth\": [self.create_constraints_prompt, self.create_deepen_prompt,\n",
    "                         self.create_concretizing_prompt, self.create_reasoning_prompt],\n",
    "            \"in_breadth\": self.create_breadth_prompt\n",
    "        }\n",
    "\n",
    "    def evolve_instruction(self, instruction: str) -> str:\n",
    "        evolution_type = \"in_depth\" if random.random() < 0.5 else \"in_breadth\"\n",
    "        operation = random.choice(self.operations[evolution_type])\n",
    "        evolved_instruction = operation(instruction)\n",
    "\n",
    "        # Send the evolved_instruction to the LLM for generating the response\n",
    "        response = self.llm(evolved_instruction)\n",
    "        return response\n",
    "\n",
    "    def create_constraints_prompt(self, instruction):\n",
    "        method_description = \"Please add one more constraints/requirements into #The Given Prompt#\"\n",
    "        prompt = base_instruction.format(method_description)\n",
    "        prompt += f\"#The Given Prompt#:\\r\\n{instruction}\\r\\n\"\n",
    "        prompt += \"#Rewritten Prompt#:\\r\\n\"\n",
    "        return prompt\n",
    "\n",
    "    def create_deepen_prompt(self, instruction):\n",
    "        method_description = \"If #The Given Prompt# contains inquiries about certain issues, the depth and breadth of the inquiry can be increased.\"\n",
    "        prompt = base_instruction.format(method_description)\n",
    "        prompt += f\"#The Given Prompt#:\\r\\n{instruction}\\r\\n\"\n",
    "        prompt += \"#Rewritten Prompt#:\\r\\n\"\n",
    "        return prompt\n",
    "\n",
    "    def create_concretizing_prompt(self, instruction):\n",
    "        method_description = \"Please replace general concepts with more specific concepts.\"\n",
    "        prompt = base_instruction.format(method_description)\n",
    "        prompt += f\"#The Given Prompt#:\\r\\n{instruction}\\r\\n\"\n",
    "        prompt += \"#Rewritten Prompt#:\\r\\n\"\n",
    "        return prompt\n",
    "\n",
    "    def create_reasoning_prompt(self, instruction):\n",
    "        method_description = \"If #The Given Prompt# can be solved with just a few simple thinking processes, you can rewrite it to explicitly request multiple-step reasoning.\"\n",
    "        prompt = base_instruction.format(method_description)\n",
    "        prompt += f\"#The Given Prompt#:\\r\\n{instruction}\\r\\n\"\n",
    "        prompt += \"#Rewritten Prompt#:\\r\\n\"\n",
    "        return prompt\n",
    "\n",
    "    def create_breadth_prompt(self, instruction):\n",
    "        prompt = base_instruction_breadth\n",
    "        prompt += f\"\\n#Given Prompt#:\\n{instruction}\\n\"\n",
    "        prompt += \"#Created Prompt#:\\n\"\n",
    "        return prompt\n",
    "\n",
    "    \n",
    "class EvalEliminator:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    def eliminate(self, instructions: list[str]) -> list[str]:\n",
    "        valid_instructions = []\n",
    "        for instruction in instructions:\n",
    "            response = self.llm(instruction)  # Simulating a response from the LLM\n",
    "            if not self.is_failure(instruction, response):\n",
    "                valid_instructions.append(instruction)\n",
    "        return valid_instructions\n",
    "\n",
    "    def is_failure(self, instruction: str, response: str) -> bool:\n",
    "        return self.lacks_information_gain(instruction, response) or \\\n",
    "            self.is_difficult_for_llm(response) or \\\n",
    "            self.is_only_stop_words(response) or \\\n",
    "            self.copies_prompt_words(instruction)\n",
    "\n",
    "    def lacks_information_gain(self, instruction: str, response: str) -> bool:\n",
    "        # Placeholder for information gain check\n",
    "        # This would involve comparing the original instruction and the response\n",
    "        # to determine if there's significant new information or complexity.\n",
    "        # The actual implementation depends on the specifics in Appendix G.\n",
    "        pass\n",
    "\n",
    "    def is_difficult_for_llm(self, response: str) -> bool:\n",
    "        return \"sorry\" in response and len(response.split()) < 80\n",
    "\n",
    "    def is_only_stop_words(self, response: str) -> bool:\n",
    "        # Check if response contains only punctuation and stop words\n",
    "        # A more sophisticated implementation might be needed for a full check.\n",
    "        return not bool(re.search(r'\\b\\w+\\b', response) and not re.fullmatch(r'[.,!?;]+', response))\n",
    "\n",
    "    def copies_prompt_words(self, instruction: str) -> bool:\n",
    "        # Check for phrases indicating lack of originality in the instruction\n",
    "        copied_phrases = [\"given prompt\", \"rewritten prompt\", \"#Rewritten Prompt#\"]\n",
    "        return any(phrase in instruction for phrase in copied_phrases)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9171d9838ba63855"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class OpenAIWrapper:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def generate_response(self, user_prompt, system_prompt=None):\n",
    "        messages = []\n",
    "        if system_prompt is not None:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages\n",
    "        )\n",
    "        return completion.choices[0].message"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "694596da588a96af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = OpenAIWrapper()\n",
    "evol_instruct = EvalEvolver(llm)  # Assuming llm is your language model callable\n",
    "eliminator = EvalEliminator(llm)\n",
    "\n",
    "# Evolve each evaluation and log the evolution\n",
    "current_evaluations = base_evaluations\n",
    "evolved_evaluations = []\n",
    "for evaluation in base_evaluations:\n",
    "    evolved_evaluation = evol_instruct.evolve_instruction(evaluation)\n",
    "    evolved_evaluation.append(evolved_evaluation)\n",
    "    print(f\"Original: {evaluation} -> Evolved: {evolved_evaluation}\")\n",
    "\n",
    "# Filter out failed evaluations and log the filtering\n",
    "filtered_evaluations = eliminator.eliminate(evolved_evaluations)\n",
    "for evaluation in evolved_evaluations:\n",
    "    if evaluation in filtered_evaluations:\n",
    "        print(f\"Kept: {evaluation}\")\n",
    "    else:\n",
    "        print(f\"Filtered: {evaluation}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5559e638ee723237"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
